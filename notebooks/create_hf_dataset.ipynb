{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/jax/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from datasets import load_dataset\n",
    "\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from copy import copy\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    FlaxAutoModelForSequenceClassification,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    TrainingArguments,\n",
    "    is_tensorboard_available,\n",
    ")\n",
    "\n",
    "from flax.training.common_utils import get_metrics, onehot, shard\n",
    "\n",
    "\n",
    "data_root = \"/kaggle/input/feedback-prize-effectiveness/\"\n",
    "train = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAPPING = {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}\n",
    "\n",
    "def _prepare_training_data_helper(args, tokenizer, df, is_train):\n",
    "    training_samples = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        idx = row[\"essay_id\"]\n",
    "        discourse_text = row[\"discourse_text\"]\n",
    "        discourse_type = row[\"discourse_type\"]\n",
    "\n",
    "        # if is_train:\n",
    "        #     filename = os.path.join(args.input, \"train\", idx + \".txt\")\n",
    "        # else:\n",
    "        #     filename = os.path.join(args.input, \"test\", idx + \".txt\")\n",
    "\n",
    "        # with open(filename, \"r\") as f:\n",
    "        #     text = f.read()\n",
    "\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            discourse_type + \" \" + discourse_text,\n",
    "            #text,\n",
    "            add_special_tokens=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256 ##TODO: update max_length\n",
    "        )\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "\n",
    "        sample = {\n",
    "            # \"discourse_id\": row[\"discourse_id\"],\n",
    "            \"input_ids\": input_ids,\n",
    "            # \"discourse_text\": discourse_text,\n",
    "            # \"essay_text\": text,\n",
    "            \"attention_mask\": encoded_text[\"attention_mask\"],\n",
    "        }\n",
    "\n",
    "        if \"token_type_ids\" in encoded_text:\n",
    "            sample[\"token_type_ids\"] = encoded_text[\"token_type_ids\"]\n",
    "\n",
    "        try:\n",
    "            label = row[\"discourse_effectiveness\"]\n",
    "            sample[\"labels\"] = LABEL_MAPPING[label]\n",
    "        except:\n",
    "            sample[\"labels\"] = 0\n",
    "        \n",
    "\n",
    "        training_samples.append(sample)\n",
    "    return training_samples\n",
    "\n",
    "\n",
    "def prepare_training_data(df, tokenizer, args, num_jobs, is_train):\n",
    "    training_samples = []\n",
    "\n",
    "    df_splits = np.array_split(df, num_jobs)\n",
    "\n",
    "    results = Parallel(n_jobs=num_jobs, backend=\"multiprocessing\")(\n",
    "        delayed(_prepare_training_data_helper)(args, tokenizer, df, is_train) for df in df_splits\n",
    "    )\n",
    "    for result in results:\n",
    "        training_samples.extend(result)\n",
    "\n",
    "    return training_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'kernel')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: {('classifier', 'bias'), ('bert', 'pooler', 'dense', 'kernel'), ('classifier', 'kernel'), ('bert', 'pooler', 'dense', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../configs\")\n",
    "cfg = copy(importlib.import_module(\"default_config\").cfg)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "config = AutoConfig.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    num_labels=cfg.num_labels,\n",
    "    #finetuning_task=data_args.task_name,\n",
    "    #use_auth_token=True if cfg.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    use_fast=not cfg.use_slow_tokenizer,\n",
    "    #use_auth_token=True if cfg.use_auth_token else None,\n",
    ")\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    config=config,\n",
    "    #use_auth_token=True if cfg.use_auth_token else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 87.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.55it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "https://symbolize.stripped_domain/r/?trace=7f16b57153f4,7f16b57690bf,7f&map= \n",
      "*** SIGTERM received by PID 760967 (TID 760967) on cpu 41 from PID 759496; stack trace: ***\n",
      "PC: @     0x7f16b57153f4  (unknown)  do_futex_wait.constprop.0\n",
      "    @     0x7f1533257c73        992  (unknown)\n",
      "    @     0x7f16b57690c0  (unknown)  (unknown)\n",
      "    @               0x80  (unknown)  (unknown)\n",
      "https://symbolize.stripped_domain/r/?trace=7f16b57153f4,7f1533257c72,7f16b57690bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7f151eb29000-7f15335d8b70 \n",
      "E0608 20:25:37.410636  760967 coredump_hook.cc:320] RAW: Remote crash gathering disabled for SIGTERM.\n",
      "https://symbolize.stripped_domain/r/?trace=7f15332b4cc3,7f16b57690bf,7f1533163666,7f153326d92a,7f15332734cc,7f1533272072,7f1533271b29,7f15335d1d0d,7f153325870a,7f16b57690bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7f151eb29000-7f15335d8b70 \n",
      "E0608 20:25:37.412906  760967 process_state.cc:1067] RAW: Signal 11 raised at PC: 0x7f15332b4cc3 while already in FailureSignalHandler!\n",
      "E0608 20:25:37.412936  760967 process_state.cc:1102] RAW: Raising 11 signal with default behavior\n"
     ]
    }
   ],
   "source": [
    "val_data = prepare_training_data(train.iloc[range(0, 100, 5)], tokenizer, cfg, num_jobs=96, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/working/notebooks/create_hf_dataset.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000038vscode-remote?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39marray(val_data[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "np.array(val_data[0]['input_ids']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:00<00:00, 2390.51it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2438.11it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2423.81it/s]\n",
      "  0%|          | 0/307 [00:00<?, ?it/s]2531.35it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2308.17it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2383.25it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2411.95it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2468.97it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2527.62it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2395.86it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2473.41it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2491.19it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2459.02it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2357.71it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2380.87it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2442.10it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2266.65it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 1964.37it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2451.36it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2454.66it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2445.39it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2440.57it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 1941.27it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2425.28it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2311.74it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2154.35it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2347.06it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2351.64it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2484.45it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2440.82it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2360.22it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2413.46it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2511.46it/s]\n",
      "  0%|          | 0/306 [00:00<?, ?it/s]2589.49it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2345.94it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 2515.94it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2439.88it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2445.16it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2487.99it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2515.29it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2616.21it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2436.77it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2457.56it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2602.48it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2057.87it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2598.79it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2512.64it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2481.91it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2505.68it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2531.03it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2503.57it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2439.93it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2559.55it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2525.36it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2517.58it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2577.25it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2549.93it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2048.27it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2589.64it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2531.40it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2729.66it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2570.70it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2562.58it/s]\n",
      "  0%|          | 0/306 [00:00<?, ?it/s]2614.63it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2560.28it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2578.16it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2527.61it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2744.02it/s]\n",
      "  0%|          | 0/306 [00:00<?, ?it/s]2654.21it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2669.21it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2453.22it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2593.11it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2579.49it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2494.85it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2640.41it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2549.81it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2600.52it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2757.32it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2691.24it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2601.41it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2302.27it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2605.09it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2597.37it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2591.98it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2589.64it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2249.20it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2361.81it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2327.32it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2259.24it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2285.71it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2471.49it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2481.51it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2219.13it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2517.59it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2241.59it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 2477.38it/s]\n",
      "https://symbolize.stripped_domain/r/?trace=7fbacde0a3f4,7fbacde5e0bf,7f&map= \n",
      "*** SIGTERM received by PID 1440515 (TID 1440515) on cpu 32 from PID 1437662; stack trace: ***\n",
      "PC: @     0x7fbacde0a3f4  (unknown)  do_futex_wait.constprop.0\n",
      "    @     0x7fb94ae8cc73        992  (unknown)\n",
      "    @     0x7fbacde5e0c0  (unknown)  (unknown)\n",
      "    @               0x80  (unknown)  (unknown)\n",
      "https://symbolize.stripped_domain/r/?trace=7fbacde0a3f4,7fb94ae8cc72,7fbacde5e0bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7fb93675e000-7fb94b20db70 \n",
      "E0614 19:35:26.688673 1440515 coredump_hook.cc:320] RAW: Remote crash gathering disabled for SIGTERM.\n",
      "https://symbolize.stripped_domain/r/?trace=7fb94aee9cc3,7fbacde5e0bf,7fb94ad98666,7fb94aea292a,7fb94aea84cc,7fb94aea7072,7fb94aea6b29,7fb94b206d0d,7fb94ae8d70a,7fbacde5e0bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7fb93675e000-7fb94b20db70 \n",
      "E0614 19:35:26.690700 1440515 process_state.cc:1067] RAW: Signal 11 raised at PC: 0x7fb94aee9cc3 while already in FailureSignalHandler!\n",
      "E0614 19:35:26.690712 1440515 process_state.cc:1102] RAW: Raising 11 signal with default behavior\n",
      "100%|██████████| 77/77 [00:00<00:00, 1951.84it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1940.19it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1943.01it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1975.84it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1886.21it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1964.44it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1557.70it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1938.15it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1896.35it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1961.71it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2134.28it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2089.19it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1892.35it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2034.98it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1958.15it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1958.61it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1888.64it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1942.11it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2053.29it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1920.53it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1712.08it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1853.09it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1920.31it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1988.79it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1907.11it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1990.26it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2111.95it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2085.38it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2115.46it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1961.51it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1999.08it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2040.12it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1947.91it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2138.63it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1980.98it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2050.26it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2097.63it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2106.96it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1969.57it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2188.35it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1888.33it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2197.66it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2022.47it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2049.64it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2051.16it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2090.49it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2213.76it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2203.49it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1870.65it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2113.59it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1921.12it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2180.73it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2256.44it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2085.52it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 1984.12it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2004.09it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 2197.38it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2163.67it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2175.07it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2005.06it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1937.01it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1823.59it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1856.18it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2129.94it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2084.88it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2117.94it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2131.59it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2081.40it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2208.42it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2046.47it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2112.92it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2086.35it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1984.28it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2065.95it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2198.52it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1958.13it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2222.38it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2148.49it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2075.82it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2101.99it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2067.14it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2001.56it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1950.59it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2143.94it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2005.40it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1987.49it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1728.61it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2012.33it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1967.15it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1972.41it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2028.36it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2030.64it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1885.45it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1907.81it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 1996.70it/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 2072.70it/s]\n",
      "https://symbolize.stripped_domain/r/?trace=7fbacde0a3f4,7fbacde5e0bf,7f&map= \n",
      "*** SIGTERM received by PID 1450695 (TID 1450695) on cpu 77 from PID 1437662; stack trace: ***\n",
      "PC: @     0x7fbacde0a3f4  (unknown)  do_futex_wait.constprop.0\n",
      "    @     0x7fb94ae8cc73        992  (unknown)\n",
      "    @     0x7fbacde5e0c0  (unknown)  (unknown)\n",
      "    @               0x80  (unknown)  (unknown)\n",
      "https://symbolize.stripped_domain/r/?trace=7fbacde0a3f4,7fb94ae8cc72,7fbacde5e0bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7fb93675e000-7fb94b20db70 \n",
      "E0614 19:35:36.958103 1450695 coredump_hook.cc:320] RAW: Remote crash gathering disabled for SIGTERM.\n",
      "https://symbolize.stripped_domain/r/?trace=7fb94aee9cc3,7fbacde5e0bf,7fb94ad98666,7fb94aea292a,7fb94aea84cc,7fb94aea7072,7fb94aea6b29,7fb94b206d0d,7fb94ae8d70a,7fbacde5e0bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7fb93675e000-7fb94b20db70 \n",
      "E0614 19:35:36.960036 1450695 process_state.cc:1067] RAW: Signal 11 raised at PC: 0x7fb94aee9cc3 while already in FailureSignalHandler!\n",
      "E0614 19:35:36.960061 1450695 process_state.cc:1102] RAW: Raising 11 signal with default behavior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Train: [    0     1     4 ... 36762 36763 36764]\n",
      "Valid: [    2     3     7 ... 36733 36736 36746]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "## stratified Kfold for train dataframe using discourse_type and discourse_effectiveness\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(train, train[\"discourse_type\"], train[\"discourse_effectiveness\"])):\n",
    "\n",
    "    train_temp = train.iloc[train_index]\n",
    "    valid_temp = train.iloc[valid_index]\n",
    "\n",
    "    train_data = prepare_training_data(train_temp, tokenizer, cfg, num_jobs=96, is_train=True)\n",
    "    val_data = prepare_training_data(valid_temp, tokenizer, cfg, num_jobs=96, is_train=True)\n",
    "\n",
    "    df = pd.DataFrame.from_records(train_data)\n",
    "    df.to_json(f\"/kaggle/working/folds/train_{fold}.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "    df = pd.DataFrame.from_records(val_data)\n",
    "    df.to_json(f\"/kaggle/working/folds/valid_{fold}.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "    print(\"Fold:\", fold)\n",
    "    print(\"Train:\", train_index)\n",
    "    print(\"Valid:\", valid_index)\n",
    "    print(\"\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 96.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.96it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "https://symbolize.stripped_domain/r/?trace=7f246898e3f4,7f24689e20bf,7f&map= \n",
      "*** SIGTERM received by PID 1409617 (TID 1409617) on cpu 24 from PID 1387880; stack trace: ***\n",
      "PC: @     0x7f246898e3f4  (unknown)  do_futex_wait.constprop.0\n",
      "    @     0x7f22e64c8c73        992  (unknown)\n",
      "    @     0x7f24689e20c0  (unknown)  (unknown)\n",
      "    @               0x80  (unknown)  (unknown)\n",
      "https://symbolize.stripped_domain/r/?trace=7f246898e3f4,7f22e64c8c72,7f24689e20bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7f22d1d9a000-7f22e6849b70 \n",
      "E0614 19:25:21.035746 1409617 coredump_hook.cc:320] RAW: Remote crash gathering disabled for SIGTERM.\n",
      "https://symbolize.stripped_domain/r/?trace=7f22e6525cc3,7f24689e20bf,7f22e63d4666,7f22e64de92a,7f22e64e44cc,7f22e64e3072,7f22e64e2b29,7f22e6842d0d,7f22e64c970a,7f24689e20bf,7f&map=abc33f1bfca16f4e7d925d4248b4beb3:7f22d1d9a000-7f22e6849b70 \n",
      "E0614 19:25:21.037792 1409617 process_state.cc:1067] RAW: Signal 11 raised at PC: 0x7f22e6525cc3 while already in FailureSignalHandler!\n",
      "E0614 19:25:21.037805 1409617 process_state.cc:1102] RAW: Raising 11 signal with default behavior\n"
     ]
    }
   ],
   "source": [
    "## generate test dataset\n",
    "test = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/test.csv\")\n",
    "test_data = prepare_training_data(test, tokenizer, cfg, num_jobs=96, is_train=False)\n",
    "df = pd.DataFrame.from_records(test_data)\n",
    "df.to_json(f\"/kaggle/working/folds/test.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data collator with dynamic padding\n",
    "# def train_data_collator(rng:)\n",
    "import jax\n",
    "import datasets\n",
    "from typing import Any, Callable, Dict, Optional, Tuple\n",
    "\n",
    "rng = jax.random.PRNGKey(1)#cfg.seed)\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())\n",
    "\n",
    "Array = Any\n",
    "Dataset = datasets.arrow_dataset.Dataset\n",
    "PRNGKey = Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_collator(rng: PRNGKey, dataset: Dataset, batch_size: int):\n",
    "    \"\"\"Returns shuffled batches of size `batch_size` from truncated `train dataset`, sharded over all local devices.\"\"\"\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        discourse_id, input_ids, labels = dataset[perm]['discourse_id'], dataset[perm]['input_ids'], dataset[perm]['label']\n",
    "        batch.pop(\"discourse_id\", None)\n",
    "        batch = {\"input_ids\": np.array(input_ids), \"mask\": [np.ones_like(x) for x in input_ids], \"label\": np.array(labels)}\n",
    "\n",
    "        # calculate max token length of this batch\n",
    "        batch_max = max([len(ids) for ids in batch[\"input_ids\"]])\n",
    "        # add padding\n",
    "        if tokenizer.padding_side == \"right\":\n",
    "            batch[\"input_ids\"] = [s + (batch_max - len(s)) * [tokenizer.pad_token_id] for s in batch[\"input_ids\"]]\n",
    "        else:\n",
    "            batch[\"input_ids\"] = [(batch_max - len(s)) * [tokenizer.pad_token_id] + s for s in batch[\"input_ids\"]]\n",
    "\n",
    "        batch['input_ids'] = np.stack(batch['input_ids'])\n",
    "        \n",
    "        masks = np.zeros_like(batch['input_ids'])\n",
    "        masks[batch['input_ids'] != tokenizer.pad_token_id] = 1\n",
    "        batch['mask'] = masks\n",
    "\n",
    "        batch = {k: np.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-d1b7be78207f26e9\n",
      "WARNING:datasets.builder:Reusing dataset json (/root/.cache/huggingface/datasets/json/default-d1b7be78207f26e9/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"json\", data_files=\"/kaggle/working/folds/valid_0.jsonl\", split=\"train\")\n",
    "train_loader = train_data_collator(rng, train_dataset, cfg.per_device_train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'discourse_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/working/notebooks/create_hf_dataset.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(batch)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000012vscode-remote?line=2'>3</a>\u001b[0m     batch\n",
      "\u001b[1;32m/kaggle/working/notebooks/create_hf_dataset.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain_data_collator\u001b[0;34m(rng, dataset, batch_size)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m perm \u001b[39min\u001b[39;00m perms:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000010vscode-remote?line=8'>9</a>\u001b[0m     batch \u001b[39m=\u001b[39m dataset[perm]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000010vscode-remote?line=9'>10</a>\u001b[0m     discourse_id, input_ids, labels \u001b[39m=\u001b[39m dataset[perm][\u001b[39m'\u001b[39;49m\u001b[39mdiscourse_id\u001b[39;49m\u001b[39m'\u001b[39;49m], dataset[perm][\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m], dataset[perm][\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000010vscode-remote?line=10'>11</a>\u001b[0m     batch\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mdiscourse_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/create_hf_dataset.ipynb#ch0000010vscode-remote?line=11'>12</a>\u001b[0m     batch \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39marray(input_ids), \u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m: [np\u001b[39m.\u001b[39mones_like(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m input_ids], \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39marray(labels)}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'discourse_id'"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform<unk>I think that the face is a natural landform because there is no life on Mars that we have descovered yet. If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says in paragraph 9, \"It's not easy to target Cydonia,\" in which he is saying that its not easy to know if it is a natural landform at this point. In all that they're saying, its probably a natural landform.<unk>People thought that the face was formed by alieans because they thought that there was life on Mars. though some say that life on Mars does exist, I think that there is no life on Mars.<unk>It says in paragraph 7, on April 5, 1998, Mars Global Surveyor flew over Cydonia for the first time. Michael Malin took a picture of Mars with his Orbiter Camera, that the face was a natural landform. Everyone who thought it was made by alieans even though it wasn't, was not satisfied. I think they were not satisfied because they have thought since 1976 that it was really formed by alieans.<unk>Though people were not satified about how the landform was a natural landform, in all, we new that alieans did not form the face. I would like to know how the landform was formed. we know now that life on Mars doesn't exist. <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "## decode text using tokenizer\n",
    "text = train_dataset[0]['input_ids']\n",
    "text = tokenizer.decode(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6feded5f862e2f5b544fb63d3bb6c48e49c7ae1c966055a5942297c4c48158e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('jax': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
