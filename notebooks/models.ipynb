{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/jax/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from datasets import load_dataset\n",
    "\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from copy import copy\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    FlaxAutoModel,\n",
    "    FlaxAutoModelForSequenceClassification,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    TrainingArguments,\n",
    "    is_tensorboard_available,\n",
    ")\n",
    "\n",
    "from flax.training.common_utils import get_metrics, onehot, shard\n",
    "\n",
    "\n",
    "data_root = \"/kaggle/input/feedback-prize-effectiveness/\"\n",
    "train = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../configs\")\n",
    "cfg = copy(importlib.import_module(\"elu_config\").cfg)\n",
    "cfg.model_name_or_path = \"facebook/opt-125m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "config = AutoConfig.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    num_labels=cfg.num_labels,\n",
    "    #finetuning_task=data_args.task_name,\n",
    "    #use_auth_token=True if cfg.use_auth_token else None,\n",
    ")\n",
    "cfg.use_slow_tokenizer = False\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     cfg.model_name_or_path,\n",
    "#     use_fast=False, ## FALSE FOR OPT\n",
    "#     #use_auth_token=True if cfg.use_auth_token else None,\n",
    "# )\n",
    "\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "\n",
    "# # FlaxAutoModelForSequenceClassification\n",
    "# model = FlaxAutoModel.from_pretrained(\n",
    "#     cfg.model_name_or_path,\n",
    "#     config=config,\n",
    "#     #use_auth_token=True if cfg.use_auth_token else None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "sys.path.append(\"../models/\")\n",
    "FeedbackJax = importlib.import_module(\"opt_model\").FlaxOPTForSequenceClassificationModule\n",
    "\n",
    "net = FeedbackJax(config=config)\n",
    "\n",
    "inp = tokenizer.encode_plus(\"Hello, world! Hello, world! Hello, world! Hello, world!\", return_tensors=\"jax\")\n",
    "net(**inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 31414, 6, 232, 328, 20920, 6, 232, 328, 20920, 6, 232, 328, 20920, 6, 232, 328], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 3.02k/3.02k [00:00<00:00, 2.23MB/s]\n",
      "Downloading: 100%|██████████| 2.12G/2.12G [01:21<00:00, 27.9MB/s] \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() got an unexpected keyword argument 'token_type_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/working/notebooks/models.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=3'>4</a>\u001b[0m FeedbackJax \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39mdefault_model\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mFeedbackJax\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m# Net(cfg, config_path=None, pretrained=True)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=7'>8</a>\u001b[0m FeedbackJax\u001b[39m.\u001b[39;49mfrom_text_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=8'>9</a>\u001b[0m     cfg\u001b[39m.\u001b[39;49mmodel_name_or_path,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=9'>10</a>\u001b[0m     seed\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mseed,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=10'>11</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49mfloat32,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=11'>12</a>\u001b[0m     text_from_pt\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000014vscode-remote?line=12'>13</a>\u001b[0m )\n",
      "File \u001b[0;32m/kaggle/working/notebooks/../models/default_model.py:355\u001b[0m, in \u001b[0;36mFeedbackJax.from_text_pretrained\u001b[0;34m(cls, text_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m config \u001b[39m=\u001b[39m FeedbackJaxConfig\u001b[39m.\u001b[39mfrom_text_configs(text_model\u001b[39m.\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    354\u001b[0m \u001b[39m# init model\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(config, \u001b[39m*\u001b[39;49mmodel_args, dtype\u001b[39m=\u001b[39;49mdtype, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    357\u001b[0m model\u001b[39m.\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mtext_model\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m text_model\u001b[39m.\u001b[39mparams\n\u001b[1;32m    359\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/kaggle/working/notebooks/../models/default_model.py:173\u001b[0m, in \u001b[0;36mFeedbackJax.__init__\u001b[0;34m(self, config, input_shape, seed, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     input_shape \u001b[39m=\u001b[39m ((\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), (\u001b[39m1\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m    172\u001b[0m module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_class(config\u001b[39m=\u001b[39mconfig, dtype\u001b[39m=\u001b[39mdtype, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 173\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config, module, input_shape\u001b[39m=\u001b[39;49minput_shape, seed\u001b[39m=\u001b[39;49mseed, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m/kaggle/working/transformers/src/transformers/modeling_flax_utils.py:124\u001b[0m, in \u001b[0;36mFlaxPreTrainedModel.__init__\u001b[0;34m(self, config, module, input_shape, seed, dtype, _do_init)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_initialized \u001b[39m=\u001b[39m _do_init\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m _do_init:\n\u001b[1;32m    123\u001b[0m     \u001b[39m# randomly initialized parameters\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     random_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_weights(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey, input_shape)\n\u001b[1;32m    125\u001b[0m     params_shape_tree \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39meval_shape(\u001b[39mlambda\u001b[39;00m params: params, random_params)\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/kaggle/working/notebooks/../models/default_model.py:184\u001b[0m, in \u001b[0;36mFeedbackJax.init_weights\u001b[0;34m(self, rng, input_shape)\u001b[0m\n\u001b[1;32m    181\u001b[0m params_rng, dropout_rng \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39msplit(rng)\n\u001b[1;32m    182\u001b[0m rngs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: params_rng, \u001b[39m\"\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m\"\u001b[39m: dropout_rng}\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule\u001b[39m.\u001b[39;49minit(rngs, input_ids, attention_mask, token_type_ids)[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m/kaggle/working/notebooks/../models/default_model.py:128\u001b[0m, in \u001b[0;36mFeedbackJaxModule.__call__\u001b[0;34m(self, input_ids, attention_mask, position_ids, token_type_ids, deterministic, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    116\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    117\u001b[0m     input_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ):\n\u001b[1;32m    126\u001b[0m     return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mreturn_dict\n\u001b[0;32m--> 128\u001b[0m     text_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext_model(\n\u001b[1;32m    129\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    130\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    131\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    132\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    133\u001b[0m         deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    134\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    135\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    136\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    139\u001b[0m     text_embeds \u001b[39m=\u001b[39m text_outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m    140\u001b[0m     text_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_projection(text_embeds)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/kaggle/working/jax/lib/python3.8/site-packages/flax/linen/module.py:648\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m _context\u001b[39m.\u001b[39mmodule_stack\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m)\n\u001b[1;32m    647\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    649\u001b[0m   \u001b[39mif\u001b[39;00m _context\u001b[39m.\u001b[39mcapture_stack:\n\u001b[1;32m    650\u001b[0m     filter_fn \u001b[39m=\u001b[39m _context\u001b[39m.\u001b[39mcapture_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() got an unexpected keyword argument 'token_type_ids'"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "sys.path.append(\"../models/\")\n",
    "# FeedbackJax = importlib.import_module(\"gpt2_model\").FeedbackJax\n",
    "# Net(cfg, config_path=None, pretrained=True)\n",
    "\n",
    "\n",
    "# FeedbackJax.from_text_pretrained(\n",
    "#     cfg.model_name_or_path,\n",
    "#     seed=cfg.seed,\n",
    "#     dtype=jnp.float32,\n",
    "#     text_from_pt=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 644/644 [00:00<00:00, 555kB/s]\n",
      "Downloading: 100%|██████████| 685/685 [00:00<00:00, 649kB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 2.13MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 1.09MB/s]\n",
      "Downloading: 100%|██████████| 441/441 [00:00<00:00, 326kB/s]\n",
      "Downloading: 100%|██████████| 632M/632M [00:07<00:00, 89.3MB/s] \n",
      "Some of the weights of FlaxOPTModel were initialized in float16 precision from the model checkpoint at facebook/opt-350m:\n",
      "[('decoder', 'embed_positions', 'embedding'), ('decoder', 'embed_tokens', 'embedding'), ('decoder', 'layers', '0', 'fc1', 'bias'), ('decoder', 'layers', '0', 'fc1', 'kernel'), ('decoder', 'layers', '0', 'fc2', 'bias'), ('decoder', 'layers', '0', 'fc2', 'kernel'), ('decoder', 'layers', '0', 'final_layer_norm', 'bias'), ('decoder', 'layers', '0', 'final_layer_norm', 'scale'), ('decoder', 'layers', '0', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '0', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '0', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '0', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '0', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '0', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '0', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '0', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '0', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '0', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '1', 'fc1', 'bias'), ('decoder', 'layers', '1', 'fc1', 'kernel'), ('decoder', 'layers', '1', 'fc2', 'bias'), ('decoder', 'layers', '1', 'fc2', 'kernel'), ('decoder', 'layers', '1', 'final_layer_norm', 'bias'), ('decoder', 'layers', '1', 'final_layer_norm', 'scale'), ('decoder', 'layers', '1', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '1', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '1', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '1', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '1', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '1', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '1', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '1', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '1', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '1', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '10', 'fc1', 'bias'), ('decoder', 'layers', '10', 'fc1', 'kernel'), ('decoder', 'layers', '10', 'fc2', 'bias'), ('decoder', 'layers', '10', 'fc2', 'kernel'), ('decoder', 'layers', '10', 'final_layer_norm', 'bias'), ('decoder', 'layers', '10', 'final_layer_norm', 'scale'), ('decoder', 'layers', '10', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '10', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '10', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '10', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '10', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '10', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '10', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '10', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '10', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '10', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '11', 'fc1', 'bias'), ('decoder', 'layers', '11', 'fc1', 'kernel'), ('decoder', 'layers', '11', 'fc2', 'bias'), ('decoder', 'layers', '11', 'fc2', 'kernel'), ('decoder', 'layers', '11', 'final_layer_norm', 'bias'), ('decoder', 'layers', '11', 'final_layer_norm', 'scale'), ('decoder', 'layers', '11', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '11', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '11', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '11', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '11', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '11', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '11', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '11', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '11', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '11', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '12', 'fc1', 'bias'), ('decoder', 'layers', '12', 'fc1', 'kernel'), ('decoder', 'layers', '12', 'fc2', 'bias'), ('decoder', 'layers', '12', 'fc2', 'kernel'), ('decoder', 'layers', '12', 'final_layer_norm', 'bias'), ('decoder', 'layers', '12', 'final_layer_norm', 'scale'), ('decoder', 'layers', '12', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '12', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '12', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '12', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '12', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '12', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '12', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '12', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '12', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '12', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '13', 'fc1', 'bias'), ('decoder', 'layers', '13', 'fc1', 'kernel'), ('decoder', 'layers', '13', 'fc2', 'bias'), ('decoder', 'layers', '13', 'fc2', 'kernel'), ('decoder', 'layers', '13', 'final_layer_norm', 'bias'), ('decoder', 'layers', '13', 'final_layer_norm', 'scale'), ('decoder', 'layers', '13', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '13', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '13', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '13', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '13', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '13', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '13', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '13', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '13', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '13', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '14', 'fc1', 'bias'), ('decoder', 'layers', '14', 'fc1', 'kernel'), ('decoder', 'layers', '14', 'fc2', 'bias'), ('decoder', 'layers', '14', 'fc2', 'kernel'), ('decoder', 'layers', '14', 'final_layer_norm', 'bias'), ('decoder', 'layers', '14', 'final_layer_norm', 'scale'), ('decoder', 'layers', '14', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '14', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '14', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '14', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '14', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '14', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '14', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '14', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '14', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '14', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '15', 'fc1', 'bias'), ('decoder', 'layers', '15', 'fc1', 'kernel'), ('decoder', 'layers', '15', 'fc2', 'bias'), ('decoder', 'layers', '15', 'fc2', 'kernel'), ('decoder', 'layers', '15', 'final_layer_norm', 'bias'), ('decoder', 'layers', '15', 'final_layer_norm', 'scale'), ('decoder', 'layers', '15', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '15', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '15', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '15', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '15', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '15', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '15', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '15', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '15', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '15', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '16', 'fc1', 'bias'), ('decoder', 'layers', '16', 'fc1', 'kernel'), ('decoder', 'layers', '16', 'fc2', 'bias'), ('decoder', 'layers', '16', 'fc2', 'kernel'), ('decoder', 'layers', '16', 'final_layer_norm', 'bias'), ('decoder', 'layers', '16', 'final_layer_norm', 'scale'), ('decoder', 'layers', '16', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '16', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '16', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '16', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '16', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '16', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '16', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '16', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '16', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '16', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '17', 'fc1', 'bias'), ('decoder', 'layers', '17', 'fc1', 'kernel'), ('decoder', 'layers', '17', 'fc2', 'bias'), ('decoder', 'layers', '17', 'fc2', 'kernel'), ('decoder', 'layers', '17', 'final_layer_norm', 'bias'), ('decoder', 'layers', '17', 'final_layer_norm', 'scale'), ('decoder', 'layers', '17', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '17', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '17', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '17', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '17', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '17', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '17', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '17', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '17', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '17', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '18', 'fc1', 'bias'), ('decoder', 'layers', '18', 'fc1', 'kernel'), ('decoder', 'layers', '18', 'fc2', 'bias'), ('decoder', 'layers', '18', 'fc2', 'kernel'), ('decoder', 'layers', '18', 'final_layer_norm', 'bias'), ('decoder', 'layers', '18', 'final_layer_norm', 'scale'), ('decoder', 'layers', '18', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '18', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '18', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '18', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '18', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '18', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '18', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '18', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '18', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '18', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '19', 'fc1', 'bias'), ('decoder', 'layers', '19', 'fc1', 'kernel'), ('decoder', 'layers', '19', 'fc2', 'bias'), ('decoder', 'layers', '19', 'fc2', 'kernel'), ('decoder', 'layers', '19', 'final_layer_norm', 'bias'), ('decoder', 'layers', '19', 'final_layer_norm', 'scale'), ('decoder', 'layers', '19', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '19', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '19', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '19', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '19', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '19', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '19', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '19', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '19', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '19', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '2', 'fc1', 'bias'), ('decoder', 'layers', '2', 'fc1', 'kernel'), ('decoder', 'layers', '2', 'fc2', 'bias'), ('decoder', 'layers', '2', 'fc2', 'kernel'), ('decoder', 'layers', '2', 'final_layer_norm', 'bias'), ('decoder', 'layers', '2', 'final_layer_norm', 'scale'), ('decoder', 'layers', '2', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '2', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '2', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '2', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '2', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '2', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '2', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '2', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '2', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '2', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '20', 'fc1', 'bias'), ('decoder', 'layers', '20', 'fc1', 'kernel'), ('decoder', 'layers', '20', 'fc2', 'bias'), ('decoder', 'layers', '20', 'fc2', 'kernel'), ('decoder', 'layers', '20', 'final_layer_norm', 'bias'), ('decoder', 'layers', '20', 'final_layer_norm', 'scale'), ('decoder', 'layers', '20', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '20', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '20', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '20', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '20', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '20', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '20', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '20', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '20', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '20', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '21', 'fc1', 'bias'), ('decoder', 'layers', '21', 'fc1', 'kernel'), ('decoder', 'layers', '21', 'fc2', 'bias'), ('decoder', 'layers', '21', 'fc2', 'kernel'), ('decoder', 'layers', '21', 'final_layer_norm', 'bias'), ('decoder', 'layers', '21', 'final_layer_norm', 'scale'), ('decoder', 'layers', '21', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '21', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '21', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '21', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '21', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '21', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '21', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '21', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '21', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '21', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '22', 'fc1', 'bias'), ('decoder', 'layers', '22', 'fc1', 'kernel'), ('decoder', 'layers', '22', 'fc2', 'bias'), ('decoder', 'layers', '22', 'fc2', 'kernel'), ('decoder', 'layers', '22', 'final_layer_norm', 'bias'), ('decoder', 'layers', '22', 'final_layer_norm', 'scale'), ('decoder', 'layers', '22', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '22', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '22', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '22', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '22', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '22', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '22', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '22', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '22', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '22', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '23', 'fc1', 'bias'), ('decoder', 'layers', '23', 'fc1', 'kernel'), ('decoder', 'layers', '23', 'fc2', 'bias'), ('decoder', 'layers', '23', 'fc2', 'kernel'), ('decoder', 'layers', '23', 'final_layer_norm', 'bias'), ('decoder', 'layers', '23', 'final_layer_norm', 'scale'), ('decoder', 'layers', '23', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '23', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '23', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '23', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '23', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '23', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '23', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '23', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '23', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '23', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '3', 'fc1', 'bias'), ('decoder', 'layers', '3', 'fc1', 'kernel'), ('decoder', 'layers', '3', 'fc2', 'bias'), ('decoder', 'layers', '3', 'fc2', 'kernel'), ('decoder', 'layers', '3', 'final_layer_norm', 'bias'), ('decoder', 'layers', '3', 'final_layer_norm', 'scale'), ('decoder', 'layers', '3', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '3', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '3', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '3', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '3', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '3', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '3', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '3', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '3', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '3', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '4', 'fc1', 'bias'), ('decoder', 'layers', '4', 'fc1', 'kernel'), ('decoder', 'layers', '4', 'fc2', 'bias'), ('decoder', 'layers', '4', 'fc2', 'kernel'), ('decoder', 'layers', '4', 'final_layer_norm', 'bias'), ('decoder', 'layers', '4', 'final_layer_norm', 'scale'), ('decoder', 'layers', '4', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '4', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '4', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '4', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '4', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '4', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '4', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '4', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '4', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '4', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '5', 'fc1', 'bias'), ('decoder', 'layers', '5', 'fc1', 'kernel'), ('decoder', 'layers', '5', 'fc2', 'bias'), ('decoder', 'layers', '5', 'fc2', 'kernel'), ('decoder', 'layers', '5', 'final_layer_norm', 'bias'), ('decoder', 'layers', '5', 'final_layer_norm', 'scale'), ('decoder', 'layers', '5', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '5', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '5', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '5', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '5', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '5', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '5', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '5', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '5', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '5', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '6', 'fc1', 'bias'), ('decoder', 'layers', '6', 'fc1', 'kernel'), ('decoder', 'layers', '6', 'fc2', 'bias'), ('decoder', 'layers', '6', 'fc2', 'kernel'), ('decoder', 'layers', '6', 'final_layer_norm', 'bias'), ('decoder', 'layers', '6', 'final_layer_norm', 'scale'), ('decoder', 'layers', '6', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '6', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '6', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '6', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '6', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '6', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '6', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '6', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '6', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '6', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '7', 'fc1', 'bias'), ('decoder', 'layers', '7', 'fc1', 'kernel'), ('decoder', 'layers', '7', 'fc2', 'bias'), ('decoder', 'layers', '7', 'fc2', 'kernel'), ('decoder', 'layers', '7', 'final_layer_norm', 'bias'), ('decoder', 'layers', '7', 'final_layer_norm', 'scale'), ('decoder', 'layers', '7', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '7', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '7', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '7', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '7', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '7', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '7', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '7', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '7', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '7', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '8', 'fc1', 'bias'), ('decoder', 'layers', '8', 'fc1', 'kernel'), ('decoder', 'layers', '8', 'fc2', 'bias'), ('decoder', 'layers', '8', 'fc2', 'kernel'), ('decoder', 'layers', '8', 'final_layer_norm', 'bias'), ('decoder', 'layers', '8', 'final_layer_norm', 'scale'), ('decoder', 'layers', '8', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '8', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '8', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '8', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '8', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '8', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '8', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '8', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '8', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '8', 'self_attn_layer_norm', 'scale'), ('decoder', 'layers', '9', 'fc1', 'bias'), ('decoder', 'layers', '9', 'fc1', 'kernel'), ('decoder', 'layers', '9', 'fc2', 'bias'), ('decoder', 'layers', '9', 'fc2', 'kernel'), ('decoder', 'layers', '9', 'final_layer_norm', 'bias'), ('decoder', 'layers', '9', 'final_layer_norm', 'scale'), ('decoder', 'layers', '9', 'self_attn', 'k_proj', 'bias'), ('decoder', 'layers', '9', 'self_attn', 'k_proj', 'kernel'), ('decoder', 'layers', '9', 'self_attn', 'out_proj', 'bias'), ('decoder', 'layers', '9', 'self_attn', 'out_proj', 'kernel'), ('decoder', 'layers', '9', 'self_attn', 'q_proj', 'bias'), ('decoder', 'layers', '9', 'self_attn', 'q_proj', 'kernel'), ('decoder', 'layers', '9', 'self_attn', 'v_proj', 'bias'), ('decoder', 'layers', '9', 'self_attn', 'v_proj', 'kernel'), ('decoder', 'layers', '9', 'self_attn_layer_norm', 'bias'), ('decoder', 'layers', '9', 'self_attn_layer_norm', 'scale'), ('decoder', 'project_in', 'kernel'), ('decoder', 'project_out', 'kernel')]\n",
      "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [7042, 337, 677, 29472, 1350, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoded_text = tokenizer.encode_plus(\"amsalak cocuk\",\n",
    "    add_special_tokens=False,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512 ##TODO: update max_length\n",
    ")\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-e28bd1ad825b3e9b\n",
      "WARNING:datasets.builder:Reusing dataset json (/root/.cache/huggingface/datasets/json/default-e28bd1ad825b3e9b/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    }
   ],
   "source": [
    "## data collator with dynamic padding\n",
    "# def train_data_collator(rng:)\n",
    "import jax\n",
    "import datasets\n",
    "from typing import Any, Callable, Dict, Optional, Tuple\n",
    "\n",
    "rng = jax.random.PRNGKey(1)#cfg.seed)\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())\n",
    "\n",
    "Array = Any\n",
    "Dataset = datasets.arrow_dataset.Dataset\n",
    "PRNGKey = Any\n",
    "\n",
    "\n",
    "def train_data_collator(rng: PRNGKey, dataset: Dataset, batch_size: int):\n",
    "    \"\"\"Returns shuffled batches of size `batch_size` from truncated `train dataset`, sharded over all local devices.\"\"\"\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        batch = {k: np.array(v) for k, v in batch.items()}\n",
    "        #batch = shard(batch)\n",
    "\n",
    "        yield batch\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"/kaggle/working/folds/valid_0.jsonl\", split=\"train\")\n",
    "train_loader = train_data_collator(rng, train_dataset, cfg.per_device_train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch['input_ids'].shape)    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The HuggingFace Team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import flax\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from configuration_hybrid_clip import FeedbackJaxConfig\n",
    "from flax.core.frozen_dict import FrozenDict\n",
    "from transformers import FLAX_MODEL_MAPPING, FlaxCLIPVisionModel\n",
    "from transformers.modeling_flax_utils import FlaxPreTrainedModel\n",
    "from transformers.models.clip.modeling_flax_clip import FlaxCLIPOutput\n",
    "from transformers.utils import logging\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "from transformers.utils import ModelOutput\n",
    "from transformers.modeling_flax_outputs import FlaxBaseModelOutput, FlaxBaseModelOutputWithPooling\n",
    "\n",
    "@flax.struct.dataclass\n",
    "class FeedbackJaxOutput(ModelOutput):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits_per_image:(`jnp.ndarray` of shape `(image_batch_size, text_batch_size)`):\n",
    "            The scaled dot product scores between `image_embeds` and `text_embeds`. This represents the image-text\n",
    "            similarity scores.\n",
    "    \"\"\"\n",
    "\n",
    "    logits: jnp.ndarray = None\n",
    "    def to_tuple(self) -> Tuple[Any]:\n",
    "        return tuple(\n",
    "            self[k] if k not in [\"text_model_output\", \"vision_model_output\"] else getattr(self, k).to_tuple()\n",
    "            for k in self.keys()\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class FeedbackJaxModule(nn.Module):\n",
    "    config: FeedbackJaxConfig\n",
    "    dtype: jnp.dtype = jnp.float32\n",
    "    freeze_backbones: bool = False\n",
    "    \n",
    "\n",
    "    def setup(self):\n",
    "        text_config = self.config.text_config\n",
    "\n",
    "        self.projection_dim = self.config.projection_dim\n",
    "        self.text_embed_dim = text_config.hidden_size\n",
    "\n",
    "        text_module = FLAX_MODEL_MAPPING[self.config.text_config.__class__].module_class\n",
    "\n",
    "        self.text_model = text_module(text_config, dtype=self.dtype)\n",
    "\n",
    "        self.text_projection = nn.Dense(\n",
    "            self.projection_dim,\n",
    "            dtype=self.dtype,\n",
    "            kernel_init=jax.nn.initializers.normal(0.02, dtype=self.dtype),\n",
    "            use_bias=False,\n",
    "        )\n",
    "        self.logits = nn.Dense(3)\n",
    "\n",
    "        self.logit_scale = self.param(\"logit_scale\", jax.nn.initializers.ones, []) * 20\n",
    "        # self.logit_scale = self.param(\"logit_scale\", jnp.array([20.]), [], mutable=False)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "        token_type_ids=None,\n",
    "        deterministic: bool = True,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.return_dict\n",
    "\n",
    "        text_outputs = self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            deterministic=deterministic,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        text_embeds = text_outputs[1]\n",
    "        text_embeds = self.text_projection(text_embeds)\n",
    "        logits = self.logits(text_embeds)\n",
    "\n",
    "\n",
    "        # text_embeds = text_outputs[1]\n",
    "        # if self.freeze_backbones:\n",
    "        #     text_embeds = jax.lax.stop_gradient(text_embeds)\n",
    "        # text_embeds = self.text_projection(text_embeds)\n",
    "\n",
    "        # # normalized features\n",
    "        # text_embeds = text_embeds / jnp.linalg.norm(text_embeds, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "        return FeedbackJaxOutput(\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "\n",
    "class FeedbackJax(FlaxPreTrainedModel):\n",
    "    config_class = FeedbackJaxConfig\n",
    "    module_class = FeedbackJaxModule\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: FeedbackJaxConfig,\n",
    "        input_shape: Optional[Tuple] = None,\n",
    "        seed: int = 0,\n",
    "        dtype: jnp.dtype = jnp.float32,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if input_shape is None:\n",
    "            input_shape = ((1, 1), (1, 224, 224, 3))\n",
    "        module = self.module_class(config=config, dtype=dtype, **kwargs)\n",
    "        super().__init__(config, module, input_shape=input_shape, seed=seed, dtype=dtype)\n",
    "\n",
    "    def init_weights(self, rng: jax.random.PRNGKey, input_shape: Tuple) -> FrozenDict:\n",
    "        # init input tensor\n",
    "        input_ids = jnp.zeros(input_shape[0], dtype=\"i4\")\n",
    "        token_type_ids = jnp.ones_like(input_ids)\n",
    "        attention_mask = jnp.ones_like(input_ids)\n",
    "\n",
    "        params_rng, dropout_rng = jax.random.split(rng)\n",
    "        rngs = {\"params\": params_rng, \"dropout\": dropout_rng}\n",
    "\n",
    "        return self.module.init(rngs, input_ids, attention_mask, token_type_ids)[\"params\"]\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "        token_type_ids=None,\n",
    "        params: dict = None,\n",
    "        dropout_rng: jax.random.PRNGKey = None,\n",
    "        train: bool = False,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.return_dict\n",
    "\n",
    "        if position_ids is None:\n",
    "            position_ids = jnp.broadcast_to(jnp.arange(jnp.atleast_2d(input_ids).shape[-1]), input_ids.shape)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = jnp.zeros_like(input_ids)\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = jnp.ones_like(input_ids)\n",
    "\n",
    "        # Handle any PRNG if needed\n",
    "        rngs = {}\n",
    "        if dropout_rng is not None:\n",
    "            rngs[\"dropout\"] = dropout_rng\n",
    "\n",
    "        return self.module.apply(\n",
    "            {\"params\": params or self.params},\n",
    "            jnp.array(input_ids, dtype=\"i4\"),\n",
    "            jnp.array(attention_mask, dtype=\"i4\"),\n",
    "            jnp.array(position_ids, dtype=\"i4\"),\n",
    "            jnp.array(token_type_ids, dtype=\"i4\"),\n",
    "            not train,\n",
    "            output_attentions,\n",
    "            output_hidden_states,\n",
    "            return_dict,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "    def get_text_features(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "        token_type_ids=None,\n",
    "        dropout_rng: jax.random.PRNGKey = None,\n",
    "        train=False,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            input_ids (:obj:`numpy.ndarray` of shape :obj:`(batch_size, sequence_length)`):\n",
    "                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n",
    "                provide it.\n",
    "                Indices can be obtained using :class:`~transformers.PreTrainedTokenizer`. See\n",
    "                :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__`\n",
    "                for details.\n",
    "                `What are input IDs? <../glossary.html#input-ids>`__\n",
    "        Returns:\n",
    "            text_features (:obj:`jax_xla.DeviceArray` of shape :obj:`(batch_size, output_dim`): The text embeddings\n",
    "            obtained by applying the projection layer to the pooled output of text model.\n",
    "        \"\"\"\n",
    "        if position_ids is None:\n",
    "            position_ids = jnp.broadcast_to(jnp.arange(jnp.atleast_2d(input_ids).shape[-1]), input_ids.shape)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = jnp.zeros_like(input_ids)\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = jnp.ones_like(input_ids)\n",
    "\n",
    "        # Handle any PRNG if needed\n",
    "        rngs = {}\n",
    "        if dropout_rng is not None:\n",
    "            rngs[\"dropout\"] = dropout_rng\n",
    "\n",
    "        def _get_features(module, input_ids, attention_mask, position_ids, token_type_ids, deterministic):\n",
    "            text_outputs = module.text_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                position_ids=position_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                deterministic=deterministic,\n",
    "            )\n",
    "            pooled_output = text_outputs[1]\n",
    "            text_features = module.text_projection(pooled_output)\n",
    "            logits = module.logits(text_features)\n",
    "            return logits\n",
    "\n",
    "        return self.module.apply(\n",
    "            {\"params\": self.params},\n",
    "            jnp.array(input_ids, dtype=\"i4\"),\n",
    "            jnp.array(attention_mask, dtype=\"i4\"),\n",
    "            jnp.array(position_ids, dtype=\"i4\"),\n",
    "            jnp.array(token_type_ids, dtype=\"i4\"),\n",
    "            not train,\n",
    "            method=_get_features,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_text_pretrained(\n",
    "        cls,\n",
    "        text_model_name_or_path: str = None,\n",
    "        *model_args,\n",
    "        **kwargs,\n",
    "    ) -> FlaxPreTrainedModel:\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            text_model_name_or_path (:obj: `str`, `optional`):\n",
    "                Information necessary to initiate the text model. Can be either:\n",
    "                    - A string, the `model id` of a pretrained model hosted inside a model repo on huggingface.co.\n",
    "                      Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under\n",
    "                      a user or organization name, like ``dbmdz/bert-base-german-cased``.\n",
    "                    - A path to a `directory` containing model weights saved using\n",
    "                      :func:`~transformers.FlaxPreTrainedModel.save_pretrained`, e.g., ``./my_model_directory/``.\n",
    "                    - A path or url to a `PyTorch checkpoint folder` (e.g, ``./pt_model``). In\n",
    "                      this case, ``from_pt`` should be set to :obj:`True` and a configuration object should be provided\n",
    "                      as ``config`` argument. This loading path is slower than converting the PyTorch checkpoint in\n",
    "                      a Flax model using the provided conversion scripts and loading the Flax model afterwards.\n",
    "            model_args (remaining positional arguments, `optional`):\n",
    "                All remaning positional arguments will be passed to the underlying model's ``__init__`` method.\n",
    "            kwargs (remaining dictionary of keyword arguments, `optional`):\n",
    "                Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,\n",
    "                :obj:`output_attentions=True`).\n",
    "                - To update the text configuration, use the prefix `text_` for each configuration parameter.\n",
    "                - To update the vision configuration, use the prefix `vision_` for each configuration parameter.\n",
    "                - To update the parent model configuration, do not use a prefix for each configuration parameter.\n",
    "                Behaves differently depending on whether a :obj:`config` is provided or automatically loaded.\n",
    "        \"\"\"\n",
    "\n",
    "        kwargs_text = {\n",
    "            argument[len(\"text_\") :]: value for argument, value in kwargs.items() if argument.startswith(\"text_\")\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        # remove text, vision kwargs from kwargs\n",
    "        for key in kwargs_text.keys():\n",
    "            del kwargs[\"text_\" + key]\n",
    "\n",
    "        # Load and initialize the text and vision model\n",
    "        text_model = kwargs_text.pop(\"model\", None)\n",
    "        if text_model is None:\n",
    "            assert (\n",
    "                text_model_name_or_path is not None\n",
    "            ), \"If `model` is not defined as an argument, a `text_model_name_or_path` has to be defined\"\n",
    "            from transformers import FlaxAutoModel\n",
    "\n",
    "            if \"config\" not in kwargs_text:\n",
    "                from transformers import AutoConfig\n",
    "\n",
    "                text_config = AutoConfig.from_pretrained(text_model_name_or_path)\n",
    "                kwargs_text[\"config\"] = text_config\n",
    "\n",
    "            text_model = FlaxAutoModel.from_pretrained(text_model_name_or_path, *model_args, **kwargs_text)\n",
    "\n",
    "\n",
    "        # instantiate config with corresponding kwargs\n",
    "        dtype = kwargs.pop(\"dtype\", jnp.float32)\n",
    "        config = FeedbackJaxConfig.from_text_configs(text_model.config, **kwargs)\n",
    "\n",
    "        # init model\n",
    "        model = cls(config, *model_args, dtype=dtype, **kwargs)\n",
    "\n",
    "        model.params[\"text_model\"] = text_model.params\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jnp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/working/notebooks/models.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=1'>2</a>\u001b[0m cfg\u001b[39m.\u001b[39mfrom_pt \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=3'>4</a>\u001b[0m cfg\u001b[39m.\u001b[39mfreeze_backbones \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m FeedbackJax\u001b[39m.\u001b[39mfrom_text_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=6'>7</a>\u001b[0m     cfg\u001b[39m.\u001b[39mmodel_name_or_path,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=7'>8</a>\u001b[0m     seed\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mseed,\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=8'>9</a>\u001b[0m     dtype\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=9'>10</a>\u001b[0m     text_from_pt\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=10'>11</a>\u001b[0m     freeze_backbones\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mfreeze_backbones\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=11'>12</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/models.ipynb#ch0000007vscode-remote?line=12'>13</a>\u001b[0m config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jnp' is not defined"
     ]
    }
   ],
   "source": [
    "cfg.dtype = \"int\"\n",
    "cfg.from_pt = False\n",
    "\n",
    "cfg.freeze_backbones = False\n",
    "\n",
    "model = FeedbackJax.from_text_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    seed=cfg.seed,\n",
    "    dtype=jnp.float32,\n",
    "    text_from_pt=False,\n",
    "    freeze_backbones=cfg.freeze_backbones\n",
    ")\n",
    "config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.34277314, 0.28011194, 0.3771149 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = batch.pop(\"labels\")\n",
    "outs = model(**batch)\n",
    "nn.softmax(outs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6feded5f862e2f5b544fb63d3bb6c48e49c7ae1c966055a5942297c4c48158e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('jax': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
