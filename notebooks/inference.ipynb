{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/working/notebooks/inference.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000000vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000000vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, Dict, Optional, Tuple\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000000vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000000vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset, load_metric\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000000vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "\"\"\"Minimal training script using Jax/Flax/HF\"\"\"\n",
    "import os, sys, time, json\n",
    "import argparse\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "from typing import Any, Callable, Dict, Optional, Tuple\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from flax import struct, traverse_util\n",
    "from flax.jax_utils import replicate, unreplicate\n",
    "from flax.training import train_state\n",
    "from flax.training.common_utils import get_metrics, onehot, shard\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    FlaxAutoModelForSequenceClassification,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    TrainingArguments,\n",
    "    is_tensorboard_available,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "from transformers.utils import check_min_version, get_full_repo_name\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "Array = Any\n",
    "Dataset = datasets.arrow_dataset.Dataset\n",
    "PRNGKey = Any\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.20.0.dev0\")\n",
    "\n",
    "git_folder = \"../\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "sys.path.append(f\"{git_folder}/configs\")\n",
    "# sys.path.append(\"models\")\n",
    "# sys.path.append(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/working/notebooks/inference.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=0'>1</a>\u001b[0m cfg \u001b[39m=\u001b[39m copy(importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39mdefault_config\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mcfg)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# Load pretrained model and tokenizer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=3'>4</a>\u001b[0m config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m     cfg\u001b[39m.\u001b[39mmodel_name_or_path,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m     num_labels\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mnum_labels,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m     \u001b[39m#finetuning_task=data_args.task_name,\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m     \u001b[39m#use_auth_token=True if cfg.use_auth_token else None,\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225450552d4a41582d73657276696e67227d/kaggle/working/notebooks/inference.ipynb#ch0000001vscode-remote?line=8'>9</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'copy' is not defined"
     ]
    }
   ],
   "source": [
    "cfg = copy(importlib.import_module(\"default_config\").cfg)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "config = AutoConfig.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    num_labels=cfg.num_labels,\n",
    "    #finetuning_task=data_args.task_name,\n",
    "    #use_auth_token=True if cfg.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    use_fast=not cfg.use_slow_tokenizer,\n",
    "    #use_auth_token=True if cfg.use_auth_token else None,\n",
    ")\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(\n",
    "    #cfg.model_name_or_path,\n",
    "    \"../outs/\",\n",
    "    config=config,\n",
    "    #use_auth_token=True if cfg.use_auth_token else None,\n",
    ")\n",
    "\n",
    "cfg.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embeddings', 'encoder', 'pooler'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params['bert'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    \"\"\"Train state with an Optax optimizer.\n",
    "\n",
    "    The two functions below differ depending on whether the task is classification\n",
    "    or regression.\n",
    "\n",
    "    Args:\n",
    "        logits_fn: Applied to last layer to obtain the logits.\n",
    "        loss_fn: Function to compute the loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    logits_fn: Callable = struct.field(pytree_node=False)\n",
    "\n",
    "tx = optax.adamw(\n",
    "    learning_rate=0.1, b1=0.9, b2=0.999, eps=1e-6)\n",
    "state = TrainState.create(\n",
    "            apply_fn=model.__call__,\n",
    "            params=model.params,\n",
    "            tx=tx,\n",
    "            # logits_fn=lambda logits: logits.argmax(-1),\n",
    "            logits_fn=lambda logits: logits, \n",
    "        )\n",
    "# make sure weights are replicated on each device\n",
    "state = replicate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_collator(dataset: Dataset, batch_size: int):\n",
    "    \"\"\"Returns batches of size `batch_size` from `eval dataset`, sharded over all local devices.\"\"\"\n",
    "    \n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        batch = {k: np.array(v) for k, v in batch.items()}\n",
    "        discourse_ids = batch.pop(\"discourse_id\")\n",
    "        batch = shard(batch)\n",
    "\n",
    "        yield batch, discourse_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-42c70368bcb5475d\n",
      "WARNING:datasets.builder:Reusing dataset json (/root/.cache/huggingface/datasets/json/default-42c70368bcb5475d/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    }
   ],
   "source": [
    "## github function idea: TODO reminder\n",
    "## TODO: create a script for dataset creation for train, val, test splits\n",
    "## create test dataset\n",
    "\n",
    "batch_size = 8\n",
    "test_dataset = load_dataset(\"json\", data_files=f\"/kaggle/working/folds/test.jsonl\", split=\"train\")\n",
    "test_loader  = test_data_collator(test_dataset, batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_single(input_ids):\n",
    "#     # x = jnp.array(input_ids)[jnp.newaxis, :] # for [batch_size, seq_len]\n",
    "#     x = input_ids\n",
    "#     x = jax.nn.softmax(model(x).logits)\n",
    "#     return x\n",
    "\n",
    "# p_predict_single = jax.vmap(predict_single, axis_name=\"batch\")\n",
    "\n",
    "\n",
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.logits_fn(logits)\n",
    "\n",
    "p_eval_step = jax.pmap(eval_step, axis_name=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Evaluating ...: 100%|██████████| 1/1 [00:18<00:00, 18.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'discourse_id': array(['739a6d00f44a', 'bcfae2c9a244'], dtype='<U12'), 'input_ids': array([[21360, 20980,   685, ...,     0,     0,     0],\n",
      "       [ 1583,  6461, 22084, ...,     0,     0,     0]]), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]]), 'labels': array([0, 0])}\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "preds = []\n",
    "di = []\n",
    "for batch, discourse_ids in tqdm(\n",
    "    test_loader,\n",
    "    total=len(test_dataset) // batch_size,\n",
    "    desc=\"Evaluating ...\",\n",
    "    position=2,\n",
    "):\n",
    "    labels = batch.pop(\"labels\")\n",
    "    pred = p_eval_step(state, batch)\n",
    "    preds.extend(pred)\n",
    "    di.extend(discourse_ids)\n",
    "    \n",
    "# evaluate also on leftover examples (not divisible by batch_size)\n",
    "num_leftover_samples = len(test_dataset) % batch_size\n",
    "\n",
    "# make sure leftover batch is evaluated on one device\n",
    "if num_leftover_samples > 0 and jax.process_index() == 0:\n",
    "    # take leftover samples\n",
    "    batch = test_dataset[-num_leftover_samples:]\n",
    "    batch = {k: np.array(v) for k, v in batch.items()}\n",
    "    print(batch)\n",
    "    discourse_ids = batch.pop(\"discourse_id\")\n",
    "\n",
    "    labels = batch.pop(\"labels\")\n",
    "    pred = eval_step(unreplicate(state), batch)\n",
    "    preds.extend(pred)\n",
    "    di.extend(discourse_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_ids = []\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred.shape != (1, 3):\n",
    "        expand_ids.append(i)\n",
    "        break\n",
    "for id in expand_ids:\n",
    "    preds[id] = jnp.expand_dims(preds[id], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[-6.8066797 ,  0.12095693,  5.2775683 ]], dtype=float32),\n",
       " DeviceArray([[-5.8036566,  4.351916 ,  1.1201755]], dtype=float32),\n",
       " DeviceArray([[-6.7667866 ,  0.11655698,  5.6036315 ]], dtype=float32),\n",
       " DeviceArray([[-6.131696 ,  3.0238857,  2.6651497]], dtype=float32),\n",
       " DeviceArray([[-2.6666145,  4.795038 , -2.7336974]], dtype=float32),\n",
       " DeviceArray([[-6.619154 ,  2.18402  ,  3.1526942]], dtype=float32),\n",
       " DeviceArray([[-6.4922547,  2.615754 ,  2.9109542]], dtype=float32),\n",
       " DeviceArray([[-6.6750355,  1.9154787,  4.0285406]], dtype=float32),\n",
       " DeviceArray([[-6.687419 ,  1.5453784,  3.5249007]], dtype=float32),\n",
       " DeviceArray([[-3.9098043,  6.0003743, -2.0506322]], dtype=float32)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = jax.nn.softmax(jnp.array(preds)[:, 0, :], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/sample_submission.csv\")\n",
    "sample_submission.loc[:, \"discourse_id\"] = di\n",
    "sample_submission.loc[:, \"Ineffective\"] = final_preds[:, 0]\n",
    "sample_submission.loc[:, \"Adequate\"] = final_preds[:, 1]\n",
    "sample_submission.loc[:, \"Effective\"] = final_preds[:, 2]\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.994266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.961976</td>\n",
       "      <td>0.037987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.995873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.588698</td>\n",
       "      <td>0.411240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.998889</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2e214524dbe3</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.275133</td>\n",
       "      <td>0.724825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84812fc2ab9f</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.426711</td>\n",
       "      <td>0.573242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c668ff840720</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.107831</td>\n",
       "      <td>0.892149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739a6d00f44a</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.121366</td>\n",
       "      <td>0.878602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcfae2c9a244</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective  Adequate  Effective\n",
       "0  a261b6e14276     0.000006  0.005728   0.994266\n",
       "1  5a88900e7dc1     0.000037  0.961976   0.037987\n",
       "2  9790d835736b     0.000004  0.004123   0.995873\n",
       "3  75ce6d68b67b     0.000062  0.588698   0.411240\n",
       "4  93578d946723     0.000574  0.998889   0.000537\n",
       "5  2e214524dbe3     0.000041  0.275133   0.724825\n",
       "6  84812fc2ab9f     0.000047  0.426711   0.573242\n",
       "7  c668ff840720     0.000020  0.107831   0.892149\n",
       "8  739a6d00f44a     0.000032  0.121366   0.878602\n",
       "9  bcfae2c9a244     0.000050  0.999632   0.000319"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6feded5f862e2f5b544fb63d3bb6c48e49c7ae1c966055a5942297c4c48158e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('jax': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
